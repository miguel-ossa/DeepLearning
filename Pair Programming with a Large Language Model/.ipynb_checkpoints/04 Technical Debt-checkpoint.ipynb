{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715e0ec4",
   "metadata": {},
   "source": [
    "# Lesson 4: Technical Debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5bf6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from utils import get_api_key\n",
    "import google.generativeai as palm\n",
    "from google.api_core import client_options as client_options_lib\n",
    "\n",
    "palm.configure(\n",
    "    # api_key=get_api_key(),\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    "    transport=\"rest\",\n",
    "    client_options=client_options_lib.ClientOptions(\n",
    "        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f7e27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(name='models/text-bison-001', base_model_id='', version='001', display_name='Text Bison', description='Model targeted for text generation.', input_token_limit=8196, output_token_limit=1024, supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'], temperature=0.7, top_p=0.95, top_k=40)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() \n",
    "          if 'generateText' \n",
    "          in m.supported_generation_methods]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee602468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(name='models/text-bison-001', base_model_id='', version='001', display_name='Text Bison', description='Model targeted for text generation.', input_token_limit=8196, output_token_limit=1024, supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'], temperature=0.7, top_p=0.95, top_k=40)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bison = models[0]\n",
    "model_bison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23627d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "@retry.Retry()\n",
    "def generate_text(prompt, \n",
    "                  model=model_bison, \n",
    "                  temperature=0.0):\n",
    "    return palm.generate_text(prompt=prompt,\n",
    "                              model=model,\n",
    "                              temperature=temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc5fda",
   "metadata": {},
   "source": [
    "<b>Ask an LLM to explain a complex code base</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a2b7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Complex Code Block\n",
    "# Note: Taken from https://github.com/lmoroney/odmlbook/blob/63c0825094b2f44efc5c4d3226425a51990e73d6/BookSource/Chapter08/ios/cats_vs_dogs/CatVsDogClassifierSample/ModelDataHandler/ModelDataHandler.swift\n",
    "CODE_BLOCK = \"\"\"\n",
    "// Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "//\n",
    "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "// you may not use this file except in compliance with the License.\n",
    "// You may obtain a copy of the License at\n",
    "//\n",
    "//    http://www.apache.org/licenses/LICENSE-2.0\n",
    "//\n",
    "// Unless required by applicable law or agreed to in writing, software\n",
    "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "// See the License for the specific language governing permissions and\n",
    "// limitations under the License.\n",
    "\n",
    "import CoreImage\n",
    "import TensorFlowLite\n",
    "import UIKit\n",
    "\n",
    "\n",
    "/// An inference from invoking the `Interpreter`.\n",
    "struct Inference {\n",
    "  let confidence: Float\n",
    "  let label: String\n",
    "}\n",
    "\n",
    "/// Information about a model file or labels file.\n",
    "typealias FileInfo = (name: String, extension: String)\n",
    "\n",
    "/// Information about the MobileNet model.\n",
    "enum MobileNet {\n",
    "  static let modelInfo: FileInfo = (name: \"converted_model\", extension: \"tflite\")\n",
    "}\n",
    "\n",
    "/// This class handles all data preprocessing and makes calls to run inference on a given frame\n",
    "/// by invoking the `Interpreter`. It then formats the inferences obtained and returns the top N\n",
    "/// results for a successful inference.\n",
    "class ModelDataHandler {\n",
    "\n",
    "  // MARK: - Public Properties\n",
    "\n",
    "  /// The current thread count used by the TensorFlow Lite Interpreter.\n",
    "  let threadCount: Int\n",
    "\n",
    "  let resultCount = 1\n",
    "\n",
    "  // MARK: - Model Parameters\n",
    "\n",
    "  let batchSize = 1\n",
    "  let inputChannels = 3\n",
    "  let inputWidth = 224\n",
    "  let inputHeight = 224\n",
    "\n",
    "  // MARK: - Private Properties\n",
    "\n",
    "  /// List of labels from the given labels file.\n",
    "  private var labels: [String] = [\"Cat\", \"Dog\"]\n",
    "\n",
    "  /// TensorFlow Lite `Interpreter` object for performing inference on a given model.\n",
    "  private var interpreter: Interpreter\n",
    "\n",
    "  /// Information about the alpha component in RGBA data.\n",
    "  private let alphaComponent = (baseOffset: 4, moduloRemainder: 3)\n",
    "\n",
    "  // MARK: - Initialization\n",
    "\n",
    "  /// A failable initializer for `ModelDataHandler`. A new instance is created if the model and\n",
    "  /// labels files are successfully loaded from the app's main bundle. Default `threadCount` is 1.\n",
    "  init?(modelFileInfo: FileInfo, threadCount: Int = 1) {\n",
    "    let modelFilename = modelFileInfo.name\n",
    "\n",
    "    // Construct the path to the model file.\n",
    "    guard let modelPath = Bundle.main.path(\n",
    "      forResource: modelFilename,\n",
    "      ofType: modelFileInfo.extension\n",
    "      ) else {\n",
    "        print(\"Failed to load the model file with name: \\(modelFilename).\")\n",
    "        return nil\n",
    "    }\n",
    "\n",
    "    // Specify the options for the `Interpreter`.\n",
    "    self.threadCount = threadCount\n",
    "    var options = InterpreterOptions()\n",
    "    options.threadCount = threadCount\n",
    "    do {\n",
    "      // Create the `Interpreter`.\n",
    "      interpreter = try Interpreter(modelPath: modelPath, options: options)\n",
    "    } catch let error {\n",
    "      print(\"Failed to create the interpreter with error: \\(error.localizedDescription)\")\n",
    "      return nil\n",
    "    }\n",
    "\n",
    "  }\n",
    "\n",
    "  // MARK: - Public Methods\n",
    "\n",
    "  /// Performs image preprocessing, invokes the `Interpreter`, and process the inference results.\n",
    "  func runModel(onFrame pixelBuffer: CVPixelBuffer) -> [Inference]? {\n",
    "    let sourcePixelFormat = CVPixelBufferGetPixelFormatType(pixelBuffer)\n",
    "    assert(sourcePixelFormat == kCVPixelFormatType_32ARGB ||\n",
    "      sourcePixelFormat == kCVPixelFormatType_32BGRA ||\n",
    "      sourcePixelFormat == kCVPixelFormatType_32RGBA)\n",
    "\n",
    "\n",
    "    let imageChannels = 4\n",
    "    assert(imageChannels >= inputChannels)\n",
    "\n",
    "    // Crops the image to the biggest square in the center and scales it down to model dimensions.\n",
    "    let scaledSize = CGSize(width: inputWidth, height: inputHeight)\n",
    "    guard let thumbnailPixelBuffer = pixelBuffer.centerThumbnail(ofSize: scaledSize) else {\n",
    "      return nil\n",
    "    }\n",
    "\n",
    "    let outputTensor: Tensor\n",
    "    do {\n",
    "      // Allocate memory for the model's input `Tensor`s.\n",
    "      try interpreter.allocateTensors()\n",
    "\n",
    "      // Remove the alpha component from the image buffer to get the RGB data.\n",
    "      guard let rgbData = rgbDataFromBuffer(\n",
    "        thumbnailPixelBuffer,\n",
    "        byteCount: batchSize * inputWidth * inputHeight * inputChannels\n",
    "        ) else {\n",
    "          print(\"Failed to convert the image buffer to RGB data.\")\n",
    "          return nil\n",
    "      }\n",
    "\n",
    "      // Copy the RGB data to the input `Tensor`.\n",
    "      try interpreter.copy(rgbData, toInputAt: 0)\n",
    "\n",
    "      // Run inference by invoking the `Interpreter`.\n",
    "      try interpreter.invoke()\n",
    "\n",
    "      // Get the output `Tensor` to process the inference results.\n",
    "      outputTensor = try interpreter.output(at: 0)\n",
    "    } catch let error {\n",
    "      print(\"Failed to invoke the interpreter with error: \\(error.localizedDescription)\")\n",
    "      return nil\n",
    "    }\n",
    "\n",
    "    let results = [Float32](unsafeData: outputTensor.data) ?? []\n",
    "\n",
    "    // Process the results.\n",
    "    let topNInferences = getTopN(results: results)\n",
    "\n",
    "    // Return the inference time and inference results.\n",
    "    return topNInferences\n",
    "  }\n",
    "\n",
    "  // MARK: - Private Methods\n",
    "\n",
    "  /// Returns the top N inference results sorted in descending order.\n",
    "  private func getTopN(results: [Float]) -> [Inference] {\n",
    "    // Create a zipped array of tuples [(labelIndex: Int, confidence: Float)].\n",
    "    let zippedResults = zip(labels.indices, results)\n",
    "\n",
    "    // Sort the zipped results by confidence value in descending order.\n",
    "    let sortedResults = zippedResults.sorted { $0.1 > $1.1 }.prefix(resultCount)\n",
    "\n",
    "    // Return the `Inference` results.\n",
    "    return sortedResults.map { result in Inference(confidence: result.1, label: labels[result.0]) }\n",
    "  }\n",
    "\n",
    "  /// Loads the labels from the labels file and stores them in the `labels` property.\n",
    "  private func loadLabels(fileInfo: FileInfo) {\n",
    "    let filename = fileInfo.name\n",
    "    let fileExtension = fileInfo.extension\n",
    "    guard let fileURL = Bundle.main.url(forResource: filename, withExtension: fileExtension) else {\n",
    "      fatalError(\"Labels file not found in bundle. Please add a labels file with name \" +\n",
    "        \"\\(filename).\\(fileExtension) and try again.\")\n",
    "    }\n",
    "    do {\n",
    "      let contents = try String(contentsOf: fileURL, encoding: .utf8)\n",
    "      labels = contents.components(separatedBy: .newlines)\n",
    "    } catch {\n",
    "      fatalError(\"Labels file named \\(filename).\\(fileExtension) cannot be read. Please add a \" +\n",
    "        \"valid labels file and try again.\")\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /// Returns the RGB data representation of the given image buffer with the specified `byteCount`.\n",
    "  ///\n",
    "  /// - Parameters\n",
    "  ///   - buffer: The pixel buffer to convert to RGB data.\n",
    "  ///   - byteCount: The expected byte count for the RGB data calculated using the values that the\n",
    "  ///       model was trained on: `batchSize * imageWidth * imageHeight * componentsCount`.\n",
    "  ///   - isModelQuantized: Whether the model is quantized (i.e. fixed point values rather than\n",
    "  ///       floating point values).\n",
    "  /// - Returns: The RGB data representation of the image buffer or `nil` if the buffer could not be\n",
    "  ///     converted.\n",
    "  private func rgbDataFromBuffer(\n",
    "    _ buffer: CVPixelBuffer,\n",
    "    byteCount: Int\n",
    "    ) -> Data? {\n",
    "    CVPixelBufferLockBaseAddress(buffer, .readOnly)\n",
    "    defer { CVPixelBufferUnlockBaseAddress(buffer, .readOnly) }\n",
    "    guard let mutableRawPointer = CVPixelBufferGetBaseAddress(buffer) else {\n",
    "      return nil\n",
    "    }\n",
    "    let count = CVPixelBufferGetDataSize(buffer)\n",
    "    let bufferData = Data(bytesNoCopy: mutableRawPointer, count: count, deallocator: .none)\n",
    "    var rgbBytes = [Float](repeating: 0, count: byteCount)\n",
    "    var index = 0\n",
    "    for component in bufferData.enumerated() {\n",
    "      let offset = component.offset\n",
    "      let isAlphaComponent = (offset % alphaComponent.baseOffset) == alphaComponent.moduloRemainder\n",
    "      guard !isAlphaComponent else { continue }\n",
    "      rgbBytes[index] = Float(component.element) / 255.0\n",
    "      index += 1\n",
    "    }\n",
    "\n",
    "    return rgbBytes.withUnsafeBufferPointer(Data.init)\n",
    "\n",
    "  }\n",
    "}\n",
    "\n",
    "// MARK: - Extensions\n",
    "\n",
    "extension Data {\n",
    "  /// Creates a new buffer by copying the buffer pointer of the given array.\n",
    "  ///\n",
    "  /// - Warning: The given array's element type `T` must be trivial in that it can be copied bit\n",
    "  ///     for bit with no indirection or reference-counting operations; otherwise, reinterpreting\n",
    "  ///     data from the resulting buffer has undefined behavior.\n",
    "  /// - Parameter array: An array with elements of type `T`.\n",
    "  init<T>(copyingBufferOf array: [T]) {\n",
    "    self = array.withUnsafeBufferPointer(Data.init)\n",
    "  }\n",
    "}\n",
    "\n",
    "extension Array {\n",
    "  /// Creates a new array from the bytes of the given unsafe data.\n",
    "  ///\n",
    "  /// - Warning: The array's `Element` type must be trivial in that it can be copied bit for bit\n",
    "  ///     with no indirection or reference-counting operations; otherwise, copying the raw bytes in\n",
    "  ///     the `unsafeData`'s buffer to a new array returns an unsafe copy.\n",
    "  /// - Note: Returns `nil` if `unsafeData.count` is not a multiple of\n",
    "  ///     `MemoryLayout<Element>.stride`.\n",
    "  /// - Parameter unsafeData: The data containing the bytes to turn into an array.\n",
    "  init?(unsafeData: Data) {\n",
    "\n",
    "    guard unsafeData.count % MemoryLayout<Element>.stride == 0 else { return nil }\n",
    "    #if swift(>=5.0)\n",
    "    self = unsafeData.withUnsafeBytes { .init($0.bindMemory(to: Element.self)) }\n",
    "    #else\n",
    "    self = unsafeData.withUnsafeBytes {\n",
    "      .init(UnsafeBufferPointer<Element>(\n",
    "        start: $0,\n",
    "        count: unsafeData.count / MemoryLayout<Element>.stride\n",
    "      ))\n",
    "    }\n",
    "    #endif  // swift(>=5.0)\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecd72028",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Can you please explain how this code works?\n",
    "\n",
    "{question}\n",
    "\n",
    "Use a lot of detail and make it as clear as possible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d447ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `ModelDataHandler` class is a TensorFlow Lite model handler that loads the MobileNet model and labels files, preprocesses the input image, and invokes the `Interpreter` to run inference. The results are then processed and returned.\n",
      "\n",
      "The `ModelDataHandler` class has the following properties:\n",
      "\n",
      "* `threadCount`: The current thread count used by the TensorFlow Lite Interpreter.\n",
      "* `resultCount`: The number of top results to return.\n",
      "* `batchSize`: The batch size of the input data.\n",
      "* `inputChannels`: The number of input channels.\n",
      "* `inputWidth`: The input width.\n",
      "* `inputHeight`: The input height.\n",
      "* `labels`: A list of labels from the labels file.\n",
      "* `interpreter`: A TensorFlow Lite `Interpreter` object for performing inference on a given model.\n",
      "* `alphaComponent`: Information about the alpha component in RGBA data.\n",
      "\n",
      "The `ModelDataHandler` class has the following initializers:\n",
      "\n",
      "* `init(modelFileInfo: FileInfo, threadCount: Int = 1)`: A failable initializer that creates a new instance of `ModelDataHandler` if the model and labels files are successfully loaded from the app's main bundle. Default `threadCount` is 1.\n",
      "\n",
      "The `ModelDataHandler` class has the following methods:\n",
      "\n",
      "* `runModel(onFrame pixelBuffer: CVPixelBuffer) -> [Inference]?`: Performs image preprocessing, invokes the `Interpreter`, and process the inference results.\n",
      "* `getTopN(results: [Float]) -> [Inference]`: Returns the top N inference results sorted in descending order.\n",
      "* `loadLabels(fileInfo: FileInfo)`: Loads the labels from the labels file and stores them in the `labels` property.\n",
      "* `rgbDataFromBuffer(_ buffer: CVPixelBuffer, byteCount: Int) -> Data?`: Returns the RGB data representation of the given image buffer with the specified `byteCount`.\n",
      "\n",
      "The `ModelDataHandler` class also has two extension methods:\n",
      "\n",
      "* `extension Data`: Creates a new buffer by copying the buffer pointer of the given array.\n",
      "* `extension Array`: Creates a new array from the bytes of the given unsafe data.\n",
      "\n",
      "Here is an example of how to use the `ModelDataHandler` class:\n",
      "\n",
      "```\n",
      "let modelDataHandler = ModelDataHandler(modelFileInfo: MobileNet.modelInfo)\n",
      "let inferenceResults = modelDataHandler.runModel(onFrame: pixelBuffer)\n",
      "```\n",
      "\n",
      "The `inferenceResults` array will contain the top N inference results sorted in descending order.\n"
     ]
    }
   ],
   "source": [
    "completion = generate_text(\n",
    "    prompt = prompt_template.format(question=CODE_BLOCK)\n",
    ")\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75774f",
   "metadata": {},
   "source": [
    "<b>Ask an LLM to document a complex code base</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc2d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Please write technical documentation for this code and \\n\n",
    "make it easy for a non swift developer to understand:\n",
    "\n",
    "{question}\n",
    "\n",
    "Output the results in markdown\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceabfc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ModelDataHandler\n",
      "\n",
      "The `ModelDataHandler` class handles all data preprocessing and makes calls to run inference on a given frame\n",
      "by invoking the `Interpreter`. It then formats the inferences obtained and returns the top N\n",
      "results for a successful inference.\n",
      "\n",
      "### Public Properties\n",
      "\n",
      "* `threadCount`: The current thread count used by the TensorFlow Lite Interpreter.\n",
      "* `resultCount`: The number of top results to return.\n",
      "\n",
      "### Model Parameters\n",
      "\n",
      "* `batchSize`: The number of images to be processed at a time.\n",
      "* `inputChannels`: The number of color channels in the input images.\n",
      "* `inputWidth`: The width of the input images.\n",
      "* `inputHeight`: The height of the input images.\n",
      "\n",
      "### Private Properties\n",
      "\n",
      "* `labels`: A list of labels from the given labels file.\n",
      "* `interpreter`: A TensorFlow Lite `Interpreter` object for performing inference on a given model.\n",
      "* `alphaComponent`: Information about the alpha component in RGBA data.\n",
      "\n",
      "### Initialization\n",
      "\n",
      "The `ModelDataHandler` class is initialized with a model file info and a thread count. The model file info\n",
      "is used to load the model and labels files from the app's main bundle. The thread count is used to\n",
      "specify the number of threads that the `Interpreter` should use to perform inference.\n",
      "\n",
      "### Public Methods\n",
      "\n",
      "* `runModel(onFrame:)`: Performs image preprocessing, invokes the `Interpreter`, and process the inference results.\n",
      "\n",
      "### Private Methods\n",
      "\n",
      "* `getTopN(results:)`: Returns the top N inference results sorted in descending order.\n",
      "* `loadLabels(fileInfo:)`: Loads the labels from the labels file and stores them in the `labels` property.\n",
      "* `rgbDataFromBuffer(_:byteCount:)`: Returns the RGB data representation of the given image buffer with the specified `byteCount`.\n",
      "\n",
      "## Extensions\n",
      "\n",
      "The `Data` and `Array` types are extended to support creating buffers and arrays from unsafe data.\n",
      "\n",
      "### Data\n",
      "\n",
      "The `Data` type is extended to support creating a new buffer by copying the buffer pointer of the given array.\n",
      "\n",
      "### Array\n",
      "\n",
      "The `Array` type is extended to support creating a new array from the bytes of the given unsafe data.\n",
      "\n",
      "## Output\n",
      "\n",
      "The `ModelDataHandler` class returns the top N inference results sorted in descending order. The results\n",
      "are formatted as a list of tuples, where each tuple contains the label index and confidence value for an\n",
      "inference result.\n",
      "\n",
      "For example, the following code would return a list of tuples containing the top 3 inference results for\n",
      "an image:\n",
      "\n",
      "```\n",
      "let results = ModelDataHandler.runModel(onFrame: pixelBuffer)\n",
      "\n",
      "for (index, confidence) in results {\n",
      "  print(\"Label: \\(labels[index]), Confidence: \\(confidence)\")\n",
      "}\n",
      "```\n",
      "\n",
      "The output would be similar to the following:\n",
      "\n",
      "```\n",
      "Label: Dog, Confidence: 0.99\n",
      "Label: Cat, Confidence: 0.01\n",
      "Label: Shoe, Confidence: 0.00\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "completion = generate_text(\n",
    "    prompt = prompt_template.format(question=CODE_BLOCK)\n",
    ")\n",
    "print(completion.result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
